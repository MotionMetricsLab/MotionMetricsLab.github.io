---
format: 
  revealjs:
    theme: [default, custom.scss]
    css: styles.css
    slide-number: true
    show-slide-number: all
    preview-links: auto
    embed-resources: true
    standalone: true
    progress: true
    history: true
    hash-type: number
    code-block-background: true
    highlight-style: zenburn
    code-link: false
    code-copy: hover
    code-line-numbers: false
    pagetitle: "Adventures in Moderation"
    author-meta: "Jeffrey Girard"
    date-meta: "2022-11-18"
---

::: {.my-title}
# [Adventures]{.blue}<br />in [Moderation]{.mypink}

::: {.light-silver}
[Jeffrey M. Girard]{}<br />
[University of Kansas]{.i}
:::

![](undraw_explore_re_8l4v.svg){.absolute bottom=0 right=0 width=400}
:::

# Introduction

```{r}
#| echo: false
#| message: false

library(tidyverse)
library(knitr)
library(kableExtra)
library(emmeans)
library(car)
```

## Overview

- What is moderation in ANOVA and regression models?

- What questions can (and can't) moderation answer?

- What tools can we use to test and probe interactions?

- ANOVA Examples: 2x2, 3x2

- Regression Examples: (2x2), 2xC, CxC

- What are some challenges and opportunities?

## Defining Moderation

- Moderation adds contextualization/complexity to a model

- It allows an IV's effect to ***depend on*** the values of other IVs

- It is usually tested using (bilinear) product terms

::: {.pt1 .fragment}
- There won't be just one effect of the IV for everyone...

- ...it depends on who each person is, in terms of other IVs

- *(It is like a gateway drug for mixed effects modeling)*
:::

## Example Research Questions

**Categorical-by-Categorical**
- Does the effect of exercise program on weight loss *depend on* biological sex?

::: {.pt1 .fragment}
**Categorical-by-Continuous**
- Does the effect of hours of exercise on weight loss *depend on* exercise program?
:::

::: {.pt1 .fragment}
**Continuous-by-Continuous**
- Does the effect of hours of exercise on weight loss *depend on* the effort put in?
:::

::: {.pt1 .fragment}
*Moderation is not mediation and cannot establish causation*

*Moderation hypotheses should be specific and falsifiable*
:::

## Free and Open-Source Tools 

R is a cross-platform statistical computing environment

  - <https://cran.r-project.org/>

:::{.pt1 .fragment}
RStudio adds a helpful environment for working with R

  - <https://posit.co/download/rstudio-desktop/>
:::

:::{.pt1 .fragment}
The {easystats} package adds statistics functions

  - <https://easystats.github.io/easystats/>
:::

# Example:<br />2x2 ANOVA

## Hypotheses and Data

1. Training will increase scores (relative to a control condition)

2. Training will increase scores for women more than for men

::: {.table-small}
```{r}
set.seed(2022)
n <- 200
data_2x2 <- 
  tibble(
    x1 = sample(0:1, size = n, replace = TRUE),
    x2 = sample(0:1, size = n, replace = TRUE),
    score = 5 + 0.5 * x1 - 0.6 * x2 + 0.6 * x1 * x2 + rnorm(n = n, sd = 1),
    condition = factor(x1, levels = 0:1, labels = c("control", "training")),
    gender = factor(x2, levels = 0:1, labels = c("woman", "man"))
  ) |> 
  select(score, condition, gender) |> 
  mutate(subject = row_number(), .before = 1)
kable(data_2x2) |> kable_styling() |> scroll_box(height = "360px")
```
:::

## Fitting the Model in ANOVA

- We can use the `aov()` function to fit simple ANOVAs like this

- The formula will be `DV ~ IV1 * IV2` for a two-way ANOVA

- We will then use `model_parameters()` to get Type 3 results

- Finally, we will `estimate_means()` and `estimate_contrasts()`

::: {.pt1 .fragment}
```{r}
#| echo: true
#| eval: true
#| message: false

library(easystats)
model1 <- aov(
  formula = score ~ condition * gender,
  data = data_2x2
)
```
:::

## ANOVA Model Parameters 

```{r}
#| echo: true
#| eval: false

mp1 <- model_parameters(
  model = model1, 
  contrasts = c("contr.sum", "contr.poly"), 
  type = 3
)
print(mp1)
```

::: {.pt1 .table-small .fragment .tc}
```{r}
#| echo: false
#| eval: true
#| message: false

mp1 <- model_parameters(
  model = model1, 
  contrasts = c("contr.sum", "contr.poly"), 
  type = 3
)
print_md(mp1, caption = "Model Summary", footer = "")
```
:::

## Estimating Marginal Means

```{r}
#| echo: true
#| eval: false

em1 <- estimate_means(
  model = model1, 
  at = c("condition", "gender")
)
print(em1)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

em1 <- estimate_means(
  model = model1, 
  at = c("condition", "gender")
)
print_md(em1)
```
:::

## Plotting Marginal Means

```{r}
#| echo: true
#| eval: false

plot(em1)
```

::: {.fragment}
```{r}
#| echo: false
#| eval: true

set.seed(2022)
em1 |> 
  visualisation_recipe(
    jitter = list(size = 2.5, alpha = 1/3), 
    line = list(linewidth = 1.5),
    pointrange = list(linewidth = 1.5, fatten = 7)
  ) |> 
  plot() +
  scale_y_continuous(limits = c(2.5, 8)) +
  theme_bw(base_size = 22) + 
  theme(plot.title = element_text(size = 22))
```
:::

## Estimating and Testing Contrasts

```{r}
#| echo: true
#| eval: false

ec1a <- estimate_contrasts(
  model = model1,
  contrast = "condition",
  at = "gender"
)
print(ec1a)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

ec1a <- estimate_contrasts(
  model = model1,
  contrast = "condition",
  at = "gender"
)
print_md(ec1a, footer = "Marginal contrasts estimated at condition, p-value adjustment method: Holm (1979)")
```
:::

## Estimating and Testing Contrasts

```{r}
#| echo: true
#| eval: false

ec1b <- estimate_contrasts(
  model = model1,
  contrast = "gender",
  at = "condition"
)
print(ec1b)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

ec1b <- estimate_contrasts(
  model = model1,
  contrast = "gender",
  at = "condition"
)
print_md(ec1b, footer = "Marginal contrasts estimated at gender, p-value adjustment method: Holm (1979)")
```
:::

# Example:<br />3x2 ANOVA

## Hypotheses and Data

1. Treatment will decrease symptoms (vs. control and placebo)

2. Treatment will be more effective for women than for men

::: {.table-small}
```{r}
set.seed(2022)
n <- 200
data_3x2 <- 
  tibble(
    group = factor(
      sample(0:2, size = n, replace = TRUE), 
      levels = 0:2, 
      labels = c("control", "placebo", "treatment")
    ),
    gender = factor(
      sample(0:1, size = n, replace = TRUE),
      levels = 0:1,
      labels = c("woman", "man")
    ),
    x1 = as.integer(group == "placebo"),
    x2 = as.integer(group == "treatment"),
    x3 = as.integer(gender == "woman"),
    symptoms = 5 - 1.5*x1 - 1.5*x2 - 0.1*x1*x3 - 1.0*x2*x3 + rnorm(n = n, sd = 0.5)
  ) |> 
  select(symptoms, group, gender) |> 
  mutate(patient = row_number(), .before = 1)
kable(data_3x2) |> kable_styling() |> scroll_box(height = "340px")
```
:::

## Fitting the Model in ANOVA

::: {.pt1 .fragment}
```{r}
#| echo: true
#| eval: true
#| message: false

model2 <- aov(
  formula = symptoms ~ group * gender,
  data = data_3x2
)
```
:::

## ANOVA Model Parameters 

```{r}
#| echo: true
#| eval: false

mp2 <- model_parameters(
  model = model2, 
  contrasts = c("contr.sum", "contr.poly"), 
  type = 3
)
print(mp2)
```

::: {.pt1 .table-small .fragment .tc}
```{r}
#| echo: false
#| eval: true
#| message: false

mp2 <- model_parameters(
  model = model2, 
  contrasts = c("contr.sum", "contr.poly"), 
  type = 3
)
print_md(mp2, caption = "Model Summary", footer = "")
```
:::

## Estimating Marginal Means

```{r}
#| echo: true
#| eval: false

em2 <- estimate_means(model2, at = c("group", "gender"))
print(em2)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

em2 <- estimate_means(
  model = model2, 
  at = c("group", "gender")
)
print_md(em2)
```
:::

## Plotting Marginal Means

```{r}
#| echo: true
#| eval: false

plot(em2)
```

::: {.fragment}
```{r}
#| echo: false
#| eval: true

set.seed(2022)
em2 |> 
  visualisation_recipe(
    jitter = list(size = 2.5, alpha = 1/3), 
    line = list(linewidth = 1.5),
    pointrange = list(linewidth = 1.5, fatten = 7)
  ) |> 
  plot() +
  scale_y_continuous(limits = c(1, 6)) +
  theme_bw(base_size = 22) + 
  theme(plot.title = element_text(size = 22))
```
:::

## Estimating and Testing Contrasts

```{r}
#| echo: true
#| eval: false

ec2a <- estimate_contrasts(model2, contrast = "group", at = "gender")
print(ec2a)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

ec2a <- estimate_contrasts(
  model = model2,
  contrast = "group",
  at = "gender"
)
print_md(ec2a, footer = "Marginal contrasts estimated at group, p-value adjustment method: Holm (1979)")
```
:::

## Estimating and Testing Contrasts

```{r}
#| echo: true
#| eval: false

ec2b <- estimate_contrasts(model2, contrast = "gender", at = "group")
print(ec2b)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

ec2b <- estimate_contrasts(
  model = model2,
  contrast = "gender",
  at = "group"
)
print_md(ec2b, footer = "Marginal contrasts estimated at gender, p-value adjustment method: Holm (1979)")
```
:::

# Rational for Regression

## Opportunities

- Recreate the results from ANOVA

- Incorporate continuous predictors/IVs

- Incorporate any kind/number of "covariates"

- Incorporate nonlinearity (e.g., polynomials)

- Extend to GLM for non-normal outcomes/DVs

- Extend to MLM for clustered/nested data

- Extend to SEM for latent variables

# Example:<br />2x2 Regression

## Fitting the Model in Regression

ANOVA code (for reference)

```{r}
#| echo: true
#| eval: false

model1 <- aov(
  formula = score ~ condition * gender,
  data = data_2x2
)
```


::: {.fragment .pt1}
Regression code

```{r}
#| echo: true
#| eval: true
#| message: false

model1b <- lm(
  formula = score ~ condition * gender,
  data = data_2x2
)
```
:::

## Comparing Moderation Models

::: {.table-small}
```{r}
#| echo: false
#| eval: true
#| message: false

model_parameters(model1, contrasts = c("contr.sum", "contr.poly"), type = 3) |> print_md(footer = "")
```

:::

::: {.table-small .pt1}
```{r}
#| echo: false
#| eval: true
#| message: false

model_parameters(model1b) |> print_md()
```

:::

::: {.footer}
Note the same $p$-values and that each $F$ is equal to the corresponding $t$ squared.
:::

## Extensions

By giving the `lm()` model to the same functions, we can...

::: {.fragment .pt1}
Estimate and plot (the same) marginal means

```{r}
#| echo: true
#| eval: false

em1b <- estimate_means(model1b, at = c("condition", "gender"))
print(em1b)
plot(em1b)
```
:::

::: {.fragment .pt1}
Estimate and test (the same) contrasts

```{r}
#| echo: true
#| eval: false

estimate_contrasts(model1b, contrast = "condition", at = "gender")
estimate_contrasts(model1b, contrast = "gender", at = "condition")
```
:::

# Example:<br />2xC Regression

## Hypotheses and Data

1. Exercising for a longer duration will burn more calories

2. Long swims will be more effective than long runs

::: {.table-small}
```{r}
set.seed(2022)
n <- 300
data_2xC <- 
  tibble(
    exercise = factor(
      sample(0:1, size = n, replace = TRUE), 
      levels = 0:1, 
      labels = c("run", "swim")
    ),
    duration = rnorm(n = n, mean = 2, sd = 0.5),
    x1 = as.integer(exercise == "swim"),
    calories = 90 + 200*duration + 0*x1 + 30*duration*x1 + rnorm(n = n, sd = 50)
  ) |> 
  select(calories, duration, exercise) |> 
  mutate(participant = row_number(), .before = 1)
kable(data_2xC) |> kable_styling() |> scroll_box(height = "340px")
```
:::

## Fitting the Model in Regression

::: {.pt1 .fragment}
```{r}
#| echo: true
#| eval: true
#| message: false

model3 <- lm(
  formula = calories ~ duration * exercise,
  data = data_2xC
)
```
:::

## Regression Model Parameters 

```{r}
#| echo: true
#| eval: false

mp3 <- model_parameters(model = model3)
print(mp3)
```

::: {.pt1 .table-small .fragment .tc}
```{r}
#| echo: false
#| eval: true
#| message: false

mp3 <- model_parameters(model = model3)
print_md(mp3, caption = "Model Summary")
```
:::

## Plotting the Relations

```{r}
#| echo: true
#| eval: false

plot(estimate_relation(model3))
```

::: {.fragment}
```{r}
#| echo: false
#| eval: true

set.seed(2022)
model3 |> 
  estimate_relation(preserve_range = FALSE) |> 
  visualisation_recipe(
    point = list(size = 2.5, alpha = 1/3),
    line = list(linewidth = 1.5)
  ) |> 
  plot() +
  theme_bw(base_size = 22) + 
  theme(plot.title = element_text(size = 22))
```
:::

## Estimating Simple Slopes

The slope of duration is different for running vs. swimming

We can use `estimate_slopes()` to get these "simple slopes"

::: {.pt1 .fragment}
```{r}
#| echo: true
#| eval: false

es3 <- estimate_slopes(model3, trend = "duration", at = "exercise")
print(es3)
```
:::

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

es3 <- estimate_slopes(model3, trend = "duration", at = "exercise")
print_md(es3)
```
:::

## Plotting Simple Slopes

```{r}
#| echo: true
#| eval: false

plot(es3)
```

::: {.fragment .pt1}
```{r}
#| echo: false
#| eval: true

es3 |> 
  visualisation_recipe(
    line = list(linewidth = 1.5),
    pointrange = list(linewidth = 1.5, fatten = 7)
  ) |> 
  plot() +
  theme_bw(base_size = 22) + 
  theme(plot.title = element_text(size = 22))
```
:::

## Estimating  Contrasts

```{r}
#| echo: true
#| eval: false

ec3 <- estimate_contrasts(
  model = model3, 
  contrast = "exercise", 
  at = "duration = c(1, 2, 3)"
)
print(es3b)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

ec3 <- estimate_contrasts(
  model = model3, 
  contrast = "exercise", 
  at = "duration = c(1, 2, 3)"
)
print_md(ec3, footer = "Marginal contrasts estimated at exercise, p-value adjustment method: Holm (1979)")
```
:::

# Example:<br />CxC Regression

## Hypotheses and Data {.smaller}

1. Attachment anxiety and avoidance will both predict reduced marital satisfaction

2. The lowest satisfaction will be from those high on both anxiety and avoidance

::: {.table-small}
```{r}
set.seed(2022)
n <- 300
data_CxC <- 
  tibble(
    aa_anxiety = rnorm(n = n),
    aa_avoidance = standardize(-1 + 0.4*aa_anxiety + rnorm(n = n)),
    satisfaction = 0 - 0.5*aa_anxiety - 0.3*aa_avoidance - 0.1*aa_anxiety*aa_avoidance + rnorm(n = n)
  ) |> 
  select(satisfaction, aa_anxiety, aa_avoidance) |> 
  mutate(participant = row_number(), .before = 1)
kable(data_CxC) |> kable_styling() |> scroll_box(height = "340px")
```
:::

## Fitting the Model in Regression

```{r}
#| echo: true
#| eval: true
#| message: false

model4 <- lm(
  formula = satisfaction ~ aa_anxiety * aa_avoidance,
  data = data_CxC
)
```

## Regression Model Parameters 

```{r}
#| echo: true
#| eval: false

mp4 <- model_parameters(model = model4)
print(mp4)
```

::: {.pt1 .table-small .fragment .tc}
```{r}
#| echo: false
#| eval: true
#| message: false

mp4 <- model_parameters(model = model4)
print_md(mp4, caption = "Model Summary")
```
:::

## Plotting the Relations

```{r}
#| echo: true
#| eval: false

plot(estimate_relation(model4))
```

::: {.fragment}
```{r}
#| echo: false
#| eval: true

set.seed(2022)
model4 |> 
  estimate_relation(preserve_range = FALSE) |> 
  visualisation_recipe(
    point = list(size = 2.5, alpha = 1/3),
    line = list(linewidth = 1.5)
  ) |> 
  plot() +
  theme_bw(base_size = 22) + 
  theme(plot.title = element_text(size = 22))
```
:::

## Estimating Simple Slopes

```{r}
#| echo: true
#| eval: false

estimate_slopes(
  model = model4, 
  trend = "aa_anxiety",
  at = "aa_avoidance = c(-3, -1.5, 0, 1.5, 3)",
)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

es4 <- estimate_slopes(model4, trend = "aa_anxiety", at = "aa_avoidance = c(-3, -1.5, 0, 1.5, 3)")
print_md(es4)
```
:::

## Plotting Simple Slopes

```{r}
#| echo: true
#| eval: false
es4a <- estimate_slopes(model4, trend = "aa_anxiety", 
                        at = "aa_avoidance", length = 1000)
plot(es4a)
```

::: {.fragment .pt1}
```{r}
#| echo: false
#| eval: true
#| 
es4a <- estimate_slopes(model4, trend = "aa_anxiety", at = "aa_avoidance", 
                       length = 1000)
es4a |> 
  visualisation_recipe(line = list(linewidth = 1.5)) |> 
  plot() +
  theme_bw(base_size = 22) + 
  theme(plot.title = element_text(size = 22))
```
:::

## Estimating Simple Slopes

```{r}
#| echo: true
#| eval: false

estimate_slopes(
  model = model4, 
  trend = "aa_avoidance",
  at = "aa_anxiety = c(-3, -1.5, 0, 1.5, 3)"
)
```

::: {.pt1 .fragment .table-small .tc}
```{r}
#| echo: false
#| eval: true

es4c <- estimate_slopes(model4, trend = "aa_avoidance", at = "aa_anxiety = c(-3, -1.5, 0, 1.5, 3)")
print_md(es4c)
```
:::

## Plotting Simple Slopes

```{r}
#| echo: true
#| eval: false
es4b <- estimate_slopes(model4, trend = "aa_avoidance", 
                        at = "aa_anxiety", length = 1000)
plot(es4b)
```

::: {.fragment .pt1}
```{r}
#| echo: false
#| eval: true
#| 
es4b <- estimate_slopes(model4, trend = "aa_avoidance", 
                        at = "aa_anxiety", length = 1000)
es4b |> 
  visualisation_recipe(line = list(linewidth = 1.5)) |> 
  plot() +
  theme_bw(base_size = 22) + 
  theme(plot.title = element_text(size = 22))
```
:::

# Discussion

## Challenges and Opportunities {.smaller}

- **Products are only one type of interaction (bilinear)**

  - Others include nonlinear, threshold, etc.

::: {.pt1 .fragment}
- **Measurement error gets compounded in moderation**
  
  - Testing in the SEM framework may be necessary
  
  - Multivariate outliers can have a large influence
:::

::: {.pt1 .fragment}
- **Power analysis is complicated for interactions**

  - Interactions tend to be very power hungry
  
  - Simulation-based power analysis may be needed
:::

::: {.pt1 .fragment}
- **Interpretations may differ between scales in GLM**

  - Caution and justification are warranted
:::

## References

::: {style="font-size: 17pt;"}
- Bauer, D. J., & Curran, P. J. (2005). Probing interactions in fixed and multilevel regression: Inferential and graphical techniques. *Multivariate Behavioral Research, 40*(3), 373–400. <https://doi.org/10/d5wzg5>

- Esarey, J., & Sumner, J. L. (2018). Marginal effects in interaction models: Determining and controlling the false positive rate. *Comparative Political Studies, 51*(9), 1144–1176. <https://doi.org/10/gdw8xw>

- Finsaas, M. C., & Goldstein, B. L. (2021). Do simple slopes follow-up tests lead us astray? Advancements in the visualization and reporting of interactions. *Psychological Methods, 26*(1), 38–60. <https://doi.org/10/ggsng9>

- McCabe, C. J., Kim, D. S., & King, K. M. (2018). Improving present practices in the visual display of interactions. *Advances in Methods and Practices in Psychological Science, 1*(2), 147–165. <https://doi.org/10/gf5sqb>

- McClelland, G. H., & Judd, C. M. (1993). Statistical difficulties of detecting interactions and moderator effects. *Psychological Bulletin, 114*(2), 376–390. <https://doi.org/10/cj3kvv>

- Miller, J. W., Stromeyer, W. R., & Schwieterman, M. A. (2013). Extensions of the Johnson-Neyman technique to linear models with curvilinear effects: Derivations and analytical tools. *Multivariate Behavioral Research, 48*(2), 267–300. <https://doi.org/10/ggwpvb>

- Rohrer, J. M., & Arslan, R. C. (2021). Precise answers to vague questions: Issues with interactions. *Advances in Methods and Practices in Psychological Science, 4*(2), 1–19. <https://doi.org/10/gk9zkd>

:::
