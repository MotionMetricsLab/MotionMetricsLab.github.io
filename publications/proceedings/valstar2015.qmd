---
title: "FERA 2015 - Second Facial Expression Recognition and Analysis challenge"
type: "proceeding"
author: "Valstar, Almaev, Girard, et al."
year: "2015"
publication: "FG"
preprint: ""
doi: "https://doi.org/10.1109/FG.2015.7284874"
materials: ""
toc: false
categories:
  - methodological
  - nonverbal behavior
  - machine learning
  - proceeding
---

## Citation (APA 7)

> Valstar, M. F., Almaev, T., Girard, J. M., Mckeown, G., Mehu, M., Yin, L., Pantic, M., & Cohn, J. F. (2015). FERA 2015—Second Facial Expression Recognition and Analysis Challenge. *Proceedings of the 11th IEEE International Conference on Automatic Face & Gesture Recognition (FG)*, 1–8.

## Abstract

Despite efforts towards evaluation standards in facial expression analysis (e.g. FERA 2011), there is a need for up-to-date standardised evaluation procedures, focusing in particular on current challenges in the field. One of the challenges that is actively being addressed is the automatic estimation of expression intensities. To continue to provide a standardisation platform and to help the field progress beyond its current limitations, the FG 2015 Facial Expression Recognition and Analysis challenge (FERA 2015) will challenge participants to estimate FACS Action Unit (AU) intensity as well as AU occurrence on a common benchmark dataset with reliable manual annotations. Evaluation will be done using a clear and well-defined protocol. In this paper we present the second such challenge in automatic recognition of facial expressions, to be held in conjunction with the 11 IEEE conference on Face and Gesture Recognition, May 2015, in Ljubljana, Slovenia. Three sub-challenges are defined: the detection of AU occurrence, the estimation of AU intensity for pre-segmented data, and fully automatic AU intensity estimation. In this work we outline the evaluation protocol, the data used, and the results of a baseline method for the three sub-challenges.
